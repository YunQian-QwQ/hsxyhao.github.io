<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://hsxyhao.github.io</id>
    <title>Madara</title>
    <updated>2019-11-19T09:35:46.076Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://hsxyhao.github.io"/>
    <link rel="self" href="https://hsxyhao.github.io/atom.xml"/>
    <subtitle>这个人很懒，什么都不想写...</subtitle>
    <logo>https://hsxyhao.github.io/images/avatar.png</logo>
    <icon>https://hsxyhao.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Madara</rights>
    <entry>
        <title type="html"><![CDATA[Redis高可用]]></title>
        <id>https://hsxyhao.github.io/post/redis-gao-ke-yong</id>
        <link href="https://hsxyhao.github.io/post/redis-gao-ke-yong">
        </link>
        <updated>2019-11-19T08:19:22.000Z</updated>
        <content type="html"><![CDATA[<h1 id="复制">复制</h1>
<p>复制就是将redis节点中的数据复制完同步到其他节点中，主要是为了解决单点故障问题。在redis中参与复制一般有主节点(master)以及从节点(slave)，将数据从主节点复制到从节点，并且复制的方式是单向的，逆向复制，在建立复制关系之后主节点的数据会同步到从节点直到解除主从关系。不论是哨兵模式还是redis集群都是在复制的基础上完成的。<br>
记忆点</p>
<ol>
<li>使用方式：建立、断开复制、安全性、只读性</li>
<li>适用场景</li>
<li>复制原理：建立复制、全量复制、部分复制、心跳</li>
<li>常见问题：读写分离、数据不一致、避免全量复制</li>
</ol>
<h2 id="复制流程">复制流程</h2>
<ol>
<li>建立复制<br>
将具有复制关系的两个redis的节点一个称为master节点，另一个称为salve节点。一个主节点可以拥有多个从节点，一个从节点主能拥有一个主节点</li>
</ol>
<ul>
<li>配置文件：在redis从节点的配置文件中添加saveof ${masterHost} ${masterPort}配置</li>
<li>启动命令：在redis启动命令中加入 --saveof ${masterHost} ${masterPort}命令</li>
<li>运行时命令：在redis运行时直接使用 salveof ${masterHost} ${masterPort}命令</li>
</ul>
<ol start="2">
<li>断开复制<br>
在从节点中执行salve no one，断开复制不会清除之前同步成功的数据。</li>
<li>切换主节点<br>
在一个已经有主节点的从节点中执行salve ${newHost} ${newPort}就会切换到新的节点，但是之前同步的数据会被清空掉，这个和断开复制有点区别。</li>
</ol>
<h1 id="哨兵模式">哨兵模式</h1>
<h1 id="集群">集群</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis 持久化]]></title>
        <id>https://hsxyhao.github.io/post/redis-chi-jiu-hua</id>
        <link href="https://hsxyhao.github.io/post/redis-chi-jiu-hua">
        </link>
        <updated>2019-11-16T09:04:43.000Z</updated>
        <summary type="html"><![CDATA[<p>持久化是将Redis内存中的数据写入到磁盘中，避免发生redis故障时数据丢失，在下次服务重启的根据持久化文件即可对数据进行恢复。</p>
]]></summary>
        <content type="html"><![CDATA[<p>持久化是将Redis内存中的数据写入到磁盘中，避免发生redis故障时数据丢失，在下次服务重启的根据持久化文件即可对数据进行恢复。</p>
<!-- more -->
<h1 id="面试">面试</h1>
<p>在面试的时候如果被问到Redis持久化的时候，怎么回答比较好？我想从以下几个角度展开，一定会让面试官眼前一亮。</p>
<ul>
<li>RDB冷备份以及AOF热备份</li>
<li>fork函数</li>
<li>COW（Copy on write）写时复制机制</li>
<li>AOF命令重写</li>
</ul>
<h1 id="cow机制">COW机制</h1>
<blockquote>
<p>写入时复制（英语：Copy-on-write，简称COW）是一种计算机程序设计领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的（transparently）。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。</p>
</blockquote>
<p>上面一段话摘自<a href="https://zh.wikipedia.org/wiki/%E5%AF%AB%E5%85%A5%E6%99%82%E8%A4%87%E8%A3%BD">维基百科</a>，简单的理解就是在有多个进程请求同一个文件的时候，都会先持有这份文件，但是只有在程序试图去修改的时候，这个程序会先复制一份文件，后面的修改会基于复制的文件，不会改动源文件。这样其他的程序所持有的还是未改动的文件。</p>
<h1 id="rbd">RBD</h1>
<p>RBD是Redis持久化方式的一种，主要是基于COW机制实现的一种类似快照的持久化方式。在Redis运行中将所有的数据复制一份输出到磁盘上，其分为两种触发机制手动触发以及自动触发。</p>
<h2 id="触发机制">触发机制</h2>
<h3 id="1手动触发">1.手动触发</h3>
<p>手动触发主要依靠开发人员使用save以及bgsave命令来启动，save和bgsave主要区别在于save是阻塞式的，bgsave会fork一个子进程来进行持久化，除了在fork过程中会出现一小段时间的阻塞外，其余时间不会阻塞服务，在持久化完成之后会自动结束进行。</p>
<h3 id="2自动触发">2.自动触发</h3>
<p>除了手动触发外，还有自动触发机制，自动触发场景如下：</p>
<ul>
<li>开启save配置(save m n)，每m秒数据出现n次修改就会自动触发</li>
<li>从节点全量复制</li>
<li>执行debug reload重新加载redis</li>
<li>在没有开启AOF持久化时，执行shutdown命令</li>
</ul>
<h2 id="bgsave流程">bgsave流程</h2>
<p>bgsave命令首先会判断是否存在RBD或者AOF子进程，如果没有则创建，若存在则直接返回。紧接着父进程会fork一个子进程，fork这段时间会出现短时间阻塞，然后父进程继续响应客户端，子进程生成RBD文件，完成持久化之后通知父进程。<br>
<img src="https://hsxyhao.github.io/post-images/1573897466755.png" alt=""><br>
bgsave命令流程说明，图片摘自《Redis开发与运维》一书</p>
<h2 id="rbd文件">RBD文件</h2>
<p>RDB的保存于dir配置指定下的目录，除此之外还可以使用config set dir动态修改RDB文件的位置以及config set dbfilename动态修改RBD文件的名称，这个在线上环境的磁盘出现问题或者写满的时候有用。</p>
<h2 id="cow的运用">cow的运用</h2>
<p>fork出来的子进程需要对父进程的数据进程持久化，但是这个时候父进程会响应来自客户端的请求，对数据进行修改，如果此时出现了一个非常大的数据正在持久化，但是突然客户端来了一个删除命令，这个时候持久化就会失败。但是如果基于cow机制的话就可以避免这个问题，父进程修改的是复制出来的数据，子进程持久化的还是原来的数据没有被修改，不会受父进程的影响。</p>
<h2 id="rdb-优缺点">RDB 优缺点</h2>
<p>优点：</p>
<ul>
<li>RDB适合用来做冷备份，加载速度比AOF快<br>
缺点：</li>
<li>RDB文件的版本有很多，版本之间互相不兼容</li>
<li>不适合实时备份，fork操作会很耗性能，与redis的高性能相违背</li>
</ul>
<h1 id="aof">AOF</h1>
<p>相对于RDB来说，AOF是可以进行实时(秒级)持久化的。比较适合用来做热备份，通过配置文件中的appendonly yes来开启，appendfilename为AOF持久化的文件名，默认为appendonly.aof。</p>
<h2 id="aof工作流程">AOF工作流程</h2>
<p>AOF持久化首先会将客户端请求的命令放入到AOF缓存中，然后根据磁盘的刷新策略写入到磁盘中，当AOF文件达到上限时，会进行AOF重写，对文件进行瘦身，最后在redis重启的时候重新加载下AOF文件即可。<br>
<img src="https://hsxyhao.github.io/post-images/1573900560042.png" alt=""></p>
<h3 id="命令写入过程">命令写入过程</h3>
<p>服务端接收到客户端按照RESP协议文本格式的命令后，会将其直接写入到aof缓存区内。使用aof缓存可以提高redis的性能，以及使用不同缓存区刷新策略，可以在性能和安全方面做出平衡。<br>
AOF刷新策略</p>
<ul>
<li>always 命令写入缓冲区后，调用fsync写入到磁盘上。即没接收到一条命令就写入到磁盘上。</li>
<li>everysec 命令写入缓冲区后，同步文件操作有专门线程每秒钟同步一次。(推荐使用)</li>
<li>no 同步操作由硬盘操作，同步周期最长为30s</li>
</ul>
<h2 id="重写机制">重写机制</h2>
<p>AOF文件随着命令不断被写入体积会越来越大，但是已经同步过的命令并不是所有的命令都是有效的，有的命令是可以被优化掉，这样可以减少AOF文件体积，还可以降低加载时间。</p>
<h3 id="优化场景">优化场景</h3>
<ul>
<li>内存中已经过期的数据不会被同步。</li>
<li>旧的AOF文件中无效的命令，del、hdel、srem等。</li>
<li>命令合并，将多条命令合并成一条指令。</li>
</ul>
<h3 id="aof重写触发机制">AOF重写触发机制</h3>
<p>手动触发：bgrewriteaof<br>
自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定，简单的理解就是当前文件大小大于重写最小值并且aof文件增长率大于设置的值。</p>
<blockquote>
<p>auto-aof-rewrite-min-size表示运行AOF重写时文件最小体积，默认为64MB，auto-aof-rewrite-percentage代表当前AOF文件空间(aof_current_size)和上一次重写后的文件空间占比。自动触发时机=aof_current_size&gt;auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size) / aof_base_size &gt;= auto-aof-rewrite-percentage</p>
</blockquote>
<h3 id="aof重写流程">AOF重写流程</h3>
<p>AOFfork的子进程只是用来重写已经存在AOF文件，AOF写入还是由父进程来完成。<br>
<img src="https://hsxyhao.github.io/post-images/1574070629984.png" alt=""><br>
1.执行AOF重写请求<br>
如果当前已经存在AOF重写任务，则当次请求不执行，如果已经有bgsave正在执行，则当前请求会等待该任务执行完成后启动。<br>
2.父进程fork一个子进程用来重写AOF文件，将客户端的命令<strong>同时</strong>保存到aof_buf以及aof_rewrite_buf中</p>
<ul>
<li>3.1 原有的AOF持久化操作会正常进行，保持从aof_buf中读取数据写入到旧的aof文件中。</li>
<li>3.2 同时会将命令写入到aof_rewrite_buf中，保证命令重写操作后的数据一致性。</li>
</ul>
<p>4.子进程的重写操作会根据内存快照进行重写，生成新的aof文件。<br>
5.1子进程完成重写之后会发给父进程发送一个完成信号，父进程会更新相关的统计数据</p>
<ul>
<li>5.2父进程把aof_rewrite_buf缓冲区的数据重写到新的aof文件中</li>
<li>5.3使用新的AOF文件替换老的AOF文件</li>
</ul>
<blockquote>
<p>体会：在AOF重写过程中会有aof_buf以及aof_rewrite_buf两个缓存区，第一个aof_buf缓存区主要的目的就是用来保持原有的AOF持久化的正常进行。第二个缓冲区aof_rewrite_buf缓冲区是保存在重写期间接收到的命令，一开始我在思考的时候不是很明白，aof_buf也会保存重写期间的数据，为什么还要在保存一份到rewrite的缓存区中？主要就是aof_buf是提供给持久化操作的，在重写操作完成之后是要将旧的文件替换掉的，所有这个时候需要将重写期间的命令单独保存下来，等重写完成之后再同步rewrite的数据，从而保证了AOF的连续性。</p>
</blockquote>
<h1 id="总结">总结</h1>
<p>这篇文章主要用来概括性记录下redis持久化操作所包含的知识点，大部分内容是我整合起来的。但是基本上都是加以自己的理解写出来的，没有直接CV，当然图片是我直接抄过来的。主要目的就是大概的记录下AOF涉及到的知识点，方便后期深入了解，以及回顾的时候可以有个快速的了解。</p>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://book.douban.com/subject/26971561/">《Redis开发与运维》</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis入门知识点]]></title>
        <id>https://hsxyhao.github.io/post/rui-shi-jun-dao-redis</id>
        <link href="https://hsxyhao.github.io/post/rui-shi-jun-dao-redis">
        </link>
        <updated>2019-11-14T07:49:23.000Z</updated>
        <summary type="html"><![CDATA[<p>Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes with radius queries and streams. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.</p>
]]></summary>
        <content type="html"><![CDATA[<p>Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes with radius queries and streams. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.</p>
<!-- more -->
<p>摘要取自Redis官方的介绍，为什么要把它放在这里，我觉得这是介绍Redis最为标准的一段话，从用途、数据结构已经功能等多方面介绍，如果以后面试官叫你介绍下redis的话，我觉得可以直接把这段话背下来😌。至于为什么把Redis称为瑞士军刀，相信用过redis的人都会这么认为。</p>
<h1 id="redis-key">Redis key</h1>
<p>Redis密钥是二进制安全的，任何二进制序列的字符串都可以作为密钥，空字符串也是有效的键。虽然key的有效长度为512M，但是在日常开发中不建议把key的长度设置太长，或者过短，最友好的一种做法是将key和业务结合起来命名，一般推荐使用user:{id}这样的方式。</p>
<h1 id="数据类型"><a href="https://redis.io/topics/data-types-intro">数据类型</a></h1>
<p>从redis的官方介绍中就可以得出，redis的基础数据类型有五种，分别为：string，hash，list，set，以及zset。至于后面提到的hyperloglogs、geospatial、bitmaps的类型，有的是后面的版本增加的，有的是基础数据类型扩展来的。相对于其他的nosql数据库来说，redis的数据类型已经很充分了。redis内置的这些类型，对于学过java的同学可以使用java中的HashMap来辅助记忆，比如说string类型就是Map&lt;String,String&gt;,list类型就类比为Map&lt;String,List<String>&gt;，hash则为Map&lt;String,Map&lt;String,String&gt;&gt;。通过这样的辅助记忆，就可以很快的记住redis的数据类型，对于后期各种类型的命令使用也起到一定的帮助。从上面的类比中我们可以看到redis是一个key，value的数据存储系统，key都是字符串类型，value则对应redis着以上几种数据类型。</p>
<h2 id="1-string类型">1. string类型</h2>
<p>string类型，可以说是redis中使用到最多的一种类型了，开发中有很多开发人员把一些热点数据的序列化成json，存储到redis中，最后访问的时候后再取出来反序列化返回到客户端。<br>
<img src="https://hsxyhao.github.io/post-images/1573721308127.png" alt=""><br>
重点记忆：</p>
<ul>
<li>最大能存储512M的内容</li>
<li>value的值是可以修改的，内部采取的是一种预扩容机制来减少频繁的扩容，如图中所示，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。</li>
</ul>
<p>命令：</p>
<pre><code class="language-java">// 添加一个键值对
&gt; set key1 value1
OK
// 添加多个键值对，改名相当于多次使用set名，mset可以减少网络请求
&gt; mset key1 value1 key2 value2 
OK
// 当value是int类型的时候可以进行加减操作，超过signed long（Long.Max）则会报错
&gt; set counter 100
OK
&gt; incr counter
(integer) 101
&gt; incr counter
(integer) 102
&gt; incrby counter 50
(integer) 152
</code></pre>
<h2 id="2-list类型">2. list类型</h2>
<p>Redis中的list相当于java中的LinkedList，不是ArrayList，也就是说他是一个链表。结合*pop和*push命令可以实现队列或者栈这种数据结构。<br>
<img src="https://hsxyhao.github.io/post-images/1573722527155.gif" alt=""></p>
<h3 id="快速链表">快速链表</h3>
<p><img src="https://hsxyhao.github.io/post-images/1573801624670.png" alt=""><br>
准确的说list类型的底层实现是快速链表，普通链表在数据量量大的情况下性能是非常低的，所以需要对list进行优化。在列表开始数据量少的情况下，会直接申请一块<strong>连续</strong>的内存存储，这块内存的结构就是ziplist(压缩列表)，当数据量比较多的时候会切换成quicklist，就是多个ziplist结合成的链表。</p>
<h3 id="list扩展应用">list扩展应用</h3>
<ol>
<li>结合rpush以及lpop（或者lpush和rpop）可以实现redis版的队列，右进左出（或左进右出）。</li>
<li>使用rpush以及rpop（或者lpush和lpop）可以实现redis版的栈，右进右出（左进左出）。</li>
</ol>
<p>命令:</p>
<ul>
<li>ltrim [start_index, end_index]命令，会保留start_index和end_index之间的部分</li>
<li>lindex相当于链表的get方法，时间复杂度为O(n),index越大性能越低。</li>
</ul>
<pre><code class="language-java">&gt; rpush books python java golang
(integer) 3
&gt; lindex books 1  # O(n) 慎用
&quot;java&quot;
&gt; lrange books 0 -1  # 获取所有元素，O(n) 慎用
1) &quot;python&quot;
2) &quot;java&quot;
3) &quot;golang&quot;
&gt; ltrim books 1 -1 # O(n) 慎用
OK
&gt; lrange books 0 -1
1) &quot;java&quot;
2) &quot;golang&quot;
&gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负
OK
&gt; llen books
(integer) 0
</code></pre>
<h2 id="3-hash类型">3. hash类型</h2>
<p>hash类型可以类比成java中HashMap，一种键值对类型，只不过这里的key只能是string类型。</p>
<h3 id="rehash">rehash</h3>
<p>相信大多数java开发人员在面试的时候都会被问到rehash，这个过程在数据量大的时候是一个性能相当低的操作，而redis为了提高性能，就采取了另一种方式进行rehash——渐近式，就是在rehash的时候不立马进行rehash，保存一个新的hash结构的同时，旧的也保存下来，在后续的定时任务中，或者有hash操作的时候进行迁移，当数据迁移完成之后，旧的hash就会被新的取代。</p>
<h3 id="与string应用比较">与string应用比较</h3>
<p>hash也可以用来保存用户信息的类似操作，但是相对于string来说，hash可以保存一个用户的单个属性，在数据量以及请求非常大的情况下，获取单个属性相比较或者所有属性来说，更加节约网络流量，但是hash的存储结构消耗要高于string。</p>
<p>命令</p>
<pre><code class="language-java">&gt; hset books java &quot;think in java&quot;  # 命令行的字符串如果包含空格，要用引号括起来
(integer) 1
&gt; hset books golang &quot;concurrency in go&quot;
(integer) 1
&gt; hset books python &quot;python cookbook&quot;
(integer) 1
&gt; hgetall books  # entries()，key 和 value 间隔出现
1) &quot;java&quot;
2) &quot;think in java&quot;
3) &quot;golang&quot;
4) &quot;concurrency in go&quot;
5) &quot;python&quot;
6) &quot;python cookbook&quot;
&gt; hlen books
(integer) 3
&gt; hget books java
&quot;think in java&quot;
&gt; hset books golang &quot;learning go programming&quot;  # 因为是更新操作，所以返回 0
(integer) 0
&gt; hget books golang
&quot;learning go programming&quot;
&gt; hmset books java &quot;effective java&quot; python &quot;learning python&quot; golang &quot;modern golang programming&quot;  # 批量 set
OK
# 整形变量的自增操作
&gt; hincrby user-laoqian age 1
(integer) 30
</code></pre>
<h2 id="4-set类型">4. set类型</h2>
<p>同样的set类型可以类比为java中的HashSet，是一种键值对唯一的数据结构，大家都知道java中的HashSet是由HashMap“变异”的，相对于HashMap，HashSet的所有value都是Null。set具有自动去重的功能，可以保证set中的可以是唯一的。<br>
<img src="https://hsxyhao.github.io/post-images/1573804430835.gif" alt=""><br>
命令：</p>
<pre><code class="language-java">&gt; sadd books python
(integer) 1
&gt; sadd books python  #  重复
(integer) 0
&gt; sadd books java golang
(integer) 2
&gt; smembers books  # 注意顺序，和插入的并不一致，因为 set 是无序的
1) &quot;java&quot;
2) &quot;python&quot;
3) &quot;golang&quot;
&gt; sismember books java  # 查询某个 value 是否存在，相当于 contains(o)
(integer) 1
&gt; sismember books rust
(integer) 0
&gt; scard books  # 获取长度相当于 count()
(integer) 3
&gt; spop books  # 弹出一个
&quot;java&quot;
</code></pre>
<h2 id="5-zset有序集合">5. zset(有序集合)</h2>
<p>set是一个无序不重复集合，zset是一个有序的不重复集合，redis内部是通过跳跃链表来实现的。要想对一个链表排序，普通的链表肯定是不行的。需要对普通链表进行改进，改造后就是跳跃链表了。<br>
<img src="https://hsxyhao.github.io/post-images/1573807555093.png" alt=""><br>
上图就是跳跃链表的一个简化示意图，相信不熟悉的人看到这里肯定会懵，这个“跳跃”二字如何解释，在这里跳跃是指层与层之间的一个切换，不是元素和元素之间。层是代表高度词，所以用跳跃来形容也比较合适。</p>
<h1 id="最后">最后</h1>
<p>这里只是对Redis的基本数据类型进行一个简单记录，将所有重要的地方都记录下来，但是没有详细记录，在面试的时候如果聊到Redis，可以简单的做个大概介绍，后面再慢慢深入，后续的文章中会对文中的一些点进行详细的学习记录。本篇文章主要根据网上的资料进行总结，说不上复制，如果单纯的把别人的东西复制过来放在自己的博客上，行为上本身就是可耻的（未标明原著），其次在效果上也是微乎其微 。建议大家平时看过一些东西之后转换成自己的理解后记录下来，这样的话效果也会好很多🤓。</p>
<h1 id="相关文档">相关文档</h1>
<p><a href="https://redis.io/topics/data-types-intro">Redis官方文档</a><br>
<a href="https://juejin.im/book/5afc2e5f6fb9a07a9b362527">Redis 深度历险：核心原理与应用实践</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gridea搭建个人博客]]></title>
        <id>https://hsxyhao.github.io/post/gridea-setup</id>
        <link href="https://hsxyhao.github.io/post/gridea-setup">
        </link>
        <updated>2019-11-13T05:47:44.000Z</updated>
        <summary type="html"><![CDATA[<p>使用Gridea搭建静态博客，记录踩坑血史🤓</p>
]]></summary>
        <content type="html"><![CDATA[<p>使用Gridea搭建静态博客，记录踩坑血史🤓</p>
<!-- more -->
<h2 id="搭建教程">搭建教程</h2>
<h3 id="1github相关配置">1.github相关配置</h3>
<p>创建github pages、token以及开通oauth认证。</p>
<ol>
<li>新建一个名为XXX.github.io的仓库，就是一个普通的github仓库只不过名字需要有一定的规则</li>
<li>在github右上角进入settings页面，在进入Developer settings页面
<ul>
<li>添加一个个人访问token，添加完之后立马复制保存一下，token是一次性可见的，后面在访问的时候就会消失，那个时候只能从新创建一个了。权限选择第一个repo就行了。<br>
<img src="https://hsxyhao.github.io/post-images/1573626367969.png" alt=""></li>
<li>然后再创建一个oauth app，后面开通评论会用到。<br>
<img src="https://hsxyhao.github.io/post-images/1573626568363.jpg" alt=""></li>
</ul>
</li>
</ol>
<h3 id="2安装gridea客户端">2.安装Gridea客户端</h3>
<p>把Gridea项目克隆到本地git clone https://github.com/getgridea/gridea，按照官方的命令启动客户端，这里要使用yarn命令，没有的话安装一下。</p>
<pre><code class="language-java"># Node version &gt; v10.0.0 is requied
$ git clone https://github.com/getgridea/gridea.git
$ cd gridea
$ yarn
$ yarn electron:serve
$ yarn electron:build
</code></pre>
<h3 id="3绑定github信息">3.绑定github信息</h3>
<p>将之前创建的token、仓库、域名等信息配置一下，配置好之后保存一下。<br>
<img src="https://hsxyhao.github.io/post-images/1573627331402.jpg" alt=""></p>
<h3 id="4添加gittalk评论">4.添加Gittalk评论</h3>
<p>开通评论，需要使用到oauth账号，填写好之后，保存一下。<br>
<img src="https://hsxyhao.github.io/post-images/1573627495172.png" alt=""></p>
<h3 id="5完结散花">5.完结散花🍂</h3>
<p>最后一步，点击左下角同步一下就可以了。如果同步出现问题，请移步到文章尾部，看看是否能帮助到你。</p>
<h2 id="帮助">帮助</h2>
<p>最后再补充一下搭建过程中遇到的问题，希望能帮助的你。</p>
<h3 id="踩坑">踩坑</h3>
<ol>
<li>在所有信息配置完之后，点击同步或者检测远程连接会出现失败的情况，如果你是第一次使用Gridea的话，那么需要将Gridea的output目录初始化为一个git仓库，然后添加远程的github地址，就是刚刚建立的XXX.github.io仓库的地址，output路径在系统中的源文件夹处可以看到。如果是从hexo迁移过来的话，这个时候一般只要拷贝一下就行了，但是需要保证之前的git origin 地址是正确的。</li>
</ol>
<h2 id="参考文档">参考文档</h2>
<p>搭建过程中查阅的相关文档，其实就是官方的文档😜</p>
<ul>
<li><a href="https://gridea.dev/">Gridea文档</a></li>
<li><a href="https://fehey.com/post/hve-notes-start/">Gridea小白上手教程</a></li>
<li><a href="https://www.bilibili.com/video/av54010923">B站视频教程</a></li>
</ul>
]]></content>
    </entry>
</feed>