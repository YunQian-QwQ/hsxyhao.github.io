<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://hsxyhao.github.io</id>
    <title>Madara</title>
    <updated>2019-12-09T03:59:45.340Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://hsxyhao.github.io"/>
    <link rel="self" href="https://hsxyhao.github.io/atom.xml"/>
    <subtitle>这个人很懒，什么都不想写...</subtitle>
    <logo>https://hsxyhao.github.io/images/avatar.png</logo>
    <icon>https://hsxyhao.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Madara</rights>
    <entry>
        <title type="html"><![CDATA[Redis淘汰机制]]></title>
        <id>https://hsxyhao.github.io/post/redis-tao-tai-ji-zhi</id>
        <link href="https://hsxyhao.github.io/post/redis-tao-tai-ji-zhi">
        </link>
        <updated>2019-12-05T06:01:00.000Z</updated>
        <summary type="html"><![CDATA[<p>redis淘汰策略有哪些？lru、lfu，lru算法改进</p>
]]></summary>
        <content type="html"><![CDATA[<p>redis淘汰策略有哪些？lru、lfu，lru算法改进</p>
<!-- more -->
<h1 id="淘汰策略">淘汰策略</h1>
<blockquote>
<p>说到redis的内存淘汰机制，然我联想到之前上大学时候的手机内存不够用的问题。记得那时候买的是16G的5s，🍎手机都知道，非常耐用，用了四年都不卡，所以手机里存了大量的东西，导致手机经常提示内存不够用。我就经常删除手机里的图片，当时我的策略就是将手机里最不重要的照片以及很少会用到的照片删除掉，现在想想当初买手机的时候真应该买内存大一些的了。其实这里我删除手机照片的思考方式就有点类似redis的内存淘汰机制了。</p>
</blockquote>
<p>redis的内存淘汰机制就是为了淘汰掉一些数据，保证redis的正常服务。可以通过在配置文件中添加maxmemery-policy选择不同的淘汰策略，具体的策略有以下几种：</p>
<ul>
<li>noeviction 不进行任何淘汰操作，当内存不够时写命令会报错</li>
<li>allkeys-lru 在所有的key中查找最近<strong>最少使用</strong>的key进行淘汰</li>
<li>volatile-lru 在设置过期时间的key中查找最近<strong>最少使用</strong>的key进行淘汰</li>
<li>allkeys-random 在所有的key中随机移除某个key</li>
<li>volatile-random 在设置了过期时间的key中随机移除某个key</li>
<li>volatile-ttl 在设置了过期时间的key中，删除过期时间最早的key</li>
<li>allkeys-lfu 在所有的key中查找最近<strong>访问频率最低</strong>的key进行淘汰（4.0版本）</li>
<li>volatile-lfu 在设置过期时间的key中查找最近<strong>访问频率最低</strong>的key进行淘汰（4.0版本）</li>
</ul>
<blockquote>
<p>这里删除的key其实只删除一个，这是因为redis在执行具有申请内存的命令时，会先判断内存是否超过maxmemery，如果超过了就会基于设置的maxmemery-policy策略删除key。</p>
</blockquote>
<h1 id="lru算法">LRU算法</h1>
<p>LRU（Least Recently Used）算法，即最近最少使用使用策略，淘汰掉最近最少使用的key。想要实现LRU算法很简单，只需要为每个key添加一个最近使用时间，在内存达到上限后，添加新的key时遍历所有key剔除空闲时间(idle time)最大的，访问频率最低的可以。或者可以使用另外一种方式，将所有的key放进一个队列中，如果达到内存上线，只需要将队尾的key剔除就行了。</p>
<blockquote>
<p>不论是上述的哪种实现方式，如果直接运用在redis中，都会影响性能，这显然与redis的高性能相悖。所以redis中采用是一种近似LRU算法。</p>
</blockquote>
<h2 id="lru算法由来">lru算法由来</h2>
<p>如下图所示，分别有四个key，~代表1秒的时间间隔，第一条线A为五秒钟访问一次，第二条线B为2秒钟访问一次，第三条线C为10秒钟访问一次，第四条线D同样为10秒钟访问一次，只不过和C起始时间点不一样。|表示同一时间点，lru算法在置换key的时候会剔除空闲时间最大的key。根据lru算法的原理得知，在|时刻，D的空闲时间(idle time)是最小的，代表下一次最有可能访问的key是D，但是从整体上来看B是即将访问的key，虽然这种情况下lru算法会出现miss情况，但是在绝大多数的情况下还是可以按照期望运行的。</p>
<blockquote>
<p>这里为什么会用到置换一次呢，主要就是只有在新的key写入并且内存达到上线的时候才会出现剔除旧的key，所以置换一次就是用新的key替换旧的key。</p>
</blockquote>
<pre><code class="language-java">~~~~~A~~~~~A~~~~~A~~~~A~~~~~A~~~~~A~~|
~~B~~B~~B~~B~~B~~B~~B~~B~~B~~B~~B~~B~|
~~~~~~~~~~C~~~~~~~~~C~~~~~~~~~C~~~~~~|
~~~~~D~~~~~~~~~~D~~~~~~~~~D~~~~~~~~~D|
</code></pre>
<h2 id="为什么采用近似的lru算法">为什么采用近似的LRU算法</h2>
<p>redis中使用的LRU算法并不是真正的LRU算法，采用的是一种近似的LRU算法，如果每次添加key的时候查找所有key的最大空闲时间，显然在性能上会有所降低，本来这种剔除的策略就是一种概率的猜测，所以在选择最大的空闲时间key的时候，只要在概率上逼近真正lru算法就行了。过期算法是在redis2.8版本中加入的，并且在3.0中对其进行了优化。</p>
<p>下图对lru算法进行了一些比较，左上角是理想的lru算法效果。上层是改进版即3.0后的版本与理想的lru算法的一个比较，下面两张图是2.8版本与3.0版本进行的一个比较。那么需要怎么理解这个图呢？<br>
<img src="https://hsxyhao.github.io/post-images/1575603094713.png" alt=""><br>
在这个图里面分为三个区域</p>
<ul>
<li>最上层的浅灰色区域代表需要淘汰的key</li>
<li>中间层深灰色区域代表是旧的key</li>
<li>最下层绿色的区域代表的是新增的key</li>
</ul>
<p>在了解这三个区域之后，那么怎样理解这个算法呢，在最上层区域中残留的深灰色点表示的是未被剔除的淘汰key，深灰色区域白色的点是被剔除掉的key，但是本来不应该被剔除掉，同理，浅绿色区域白色的点也是代表被剔除的key。lru算法的好坏程度就是是不是剔除了需要淘汰的key，在上图中可以看存储redis3.0算法是最接近理想的lru算法效果。</p>
<h2 id="redis30中对lru算法的改进">redis3.0中对lru算法的改进</h2>
<p>在每次随机选取的key，都会放进一个poll(默认为16)缓存池中，这里面的key是根据每个key的空闲时间大小排序的，每次随机选择的key都需要和poll中最小的key进行比较，只有大于最小的空闲值才会被放入poll中，在每次剔除key的时候都会选择一个最大的空闲值来剔除。</p>
<p>一个redis实例中会有多个DB，对于每个DB都会创建一个poll淘汰缓存。为什么在这里单独提一下这个问题呢？在后面的LFU算法由来中会说道。</p>
<h1 id="lfu算法">LFU算法</h1>
<p>全称Least Frequently Used，与LRU不同的是，LFU是按照每个key访问频率进行淘汰的。</p>
<h2 id="由来">由来</h2>
<blockquote>
<p>Everything started from an open issue: when you have multiple databases<br>
with Redis 3.2, the algorithm evicts making local choices. So<br>
if for example you have all keys with a small idle time in DB number 0,<br>
and all keys with large idle time in DB number 1, Redis will evict<br>
one key from each DB. A more rational choice is of course to start<br>
evicting keys from DB number 1, and only later to evict the other keys.</p>
</blockquote>
<p>上面是来自作者antire写<a href="http://antirez.com/news/109">lru算法blog</a>中的一段话，这段话的意思是当有两个DB时，一个DB全是空闲时间小的key，另一个DB全是空闲时间大的key，然而这个时候比较的是各自DB中的key数据，其实应该剔除的是空闲时间大的DB。后面作者提到，不管在lru的基础上怎么优化，在性能上都提高不了，所以作者后面就开始研究新的算法即LFU算法。具体作者怎么说的可以去看原文，<a href="http://antirez.com/news/109">原文链接</a>。</p>
<h1 id="参考链接">参考链接</h1>
<ol>
<li><a href="http://antirez.com/news/109">reids作者关于LRU算法的讲解</a></li>
<li><a href="https://segmentfault.com/a/1190000017555834">redis源码分析</a></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[vim命令]]></title>
        <id>https://hsxyhao.github.io/post/vim-ming-ling-ji-lu</id>
        <link href="https://hsxyhao.github.io/post/vim-ming-ling-ji-lu">
        </link>
        <updated>2019-12-05T01:00:51.000Z</updated>
        <summary type="html"><![CDATA[<p>记录让自己尴尬的vim命令😫</p>
]]></summary>
        <content type="html"><![CDATA[<p>记录让自己尴尬的vim命令😫</p>
<!-- more -->
<p>光标行编辑</p>
<pre><code class="language-java">// 进入编辑模式
:$ 文件最后一行
:0 文件第一行
:n 文件第n-1行
$ 行尾
0 行首
</code></pre>
<p>光标全文位置跳转</p>
<pre><code class="language-java">gg 页首
G 页末
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis高可用]]></title>
        <id>https://hsxyhao.github.io/post/redis-gao-ke-yong</id>
        <link href="https://hsxyhao.github.io/post/redis-gao-ke-yong">
        </link>
        <updated>2019-11-23T09:51:53.000Z</updated>
        <summary type="html"><![CDATA[<p>Redis的高可用实现方案有哪些，为什么要选择官方的哨兵模式，自己开发自动化故障转移脚本有什么问题。redis cluster重定向有几种？redis数据分区...</p>
]]></summary>
        <content type="html"><![CDATA[<p>Redis的高可用实现方案有哪些，为什么要选择官方的哨兵模式，自己开发自动化故障转移脚本有什么问题。redis cluster重定向有几种？redis数据分区...</p>
<!-- more -->
<h1 id="主从复制的问题">主从复制的问题</h1>
<p>一旦主节点发生故障，那么系统的写能力就会崩溃，这个时候需要手动的切换主节点，手动操作的显然不是一个明智的选择，所以redis官方提供了哨兵模式。</p>
<p><strong>试想一下如果发生故障，人工操作的流程应该是怎么样的？</strong></p>
<ol>
<li>在多个从节点中选择一个节点作为新的主节点</li>
<li>对新的主节点执行slaveof no one</li>
<li>其他从节点切换到新的主节点并开始进行数据同步</li>
<li>主从节点重启后在同步新节点的数据</li>
</ol>
<p>大多数手动操作流程都是以上几个步骤，需要人工介入的方案并不是一个高可用的方案。即使使用脚本代替人工操作的方案，但是还是需要考虑以下几个问题：</p>
<ul>
<li>主节点故障，需要手动切换主节点，同步应用方的主节点地址更新，以及其他从节点同步新主节点数据</li>
<li>主节点的写能力受到单机的限制</li>
<li>主节点的存储能力受到单机的限制</li>
</ul>
<blockquote>
<p>最后两个问题应该归类为分布式类别，但是由于主从复制模式也存在这种问题，所以也列举出来。主从复制最主要的问题还是第一个问题，手动切换如果不及时的话，会给应用方数据带来一定的错误，其次故障转义在实时性以及准确性上也无法得到保障。</p>
</blockquote>
<h1 id="redis-sentinel">Redis Sentinel</h1>
<p>主节点发生故障时，Redis Sentinel能自动完成故障发现和转移。哨兵模式解决了哪些问题，为什么不直接使用脚本代替人工操作，要单独使用哨兵模式呢？</p>
<blockquote>
<p>建议使用Redis 2.8以上的版本</p>
</blockquote>
<p><strong>自动化脚本仍然无法解决的问题?</strong></p>
<ul>
<li>一、判断节点不可达的机制是否健全和标准(为什么哨兵模式中会有多个sentinel节点)</li>
<li>二、怎么保证只有一个从节点晋升为主节点(多从节点的情况下)</li>
<li>三、通知客户端更新主节点ip是否健壮</li>
</ul>
<h2 id="哨兵模式拓扑图">哨兵模式拓扑图</h2>
<p>哨兵模式是为了解决主从复制一系列问题产生的，本质上是不会修改主从复制的结构，只是在其基础上进行扩展，也就是多了一些sentinel节点，其实这里的sentinel节点也是一种特殊的redis服务几点。</p>
<figure data-type="image" tabindex="1"><img src="https://hsxyhao.github.io/post-images/1574667620983.png" alt=""></figure>
<p><strong>故障转移步骤</strong></p>
<ol>
<li>主节点出现故障，从节点与主节点的连接断开，主从复制失败。</li>
<li>每个sentinel节点通过定期监控查看主节点是否出现故障。</li>
<li>如果有多个sentinel节点都检测出主节点出现故障，则会选举出一个leader sentinel来负责故障转移的主要任务。</li>
<li>开始进行故障转移<br>
<img src="https://hsxyhao.github.io/post-images/1574668587748.png" alt=""></li>
</ol>
<blockquote>
<p>第四步将之前的主节点变为从节点，是在该节点可以重启之后进行的操作。</p>
</blockquote>
<ol start="5">
<li>完成故障转移</li>
</ol>
<h2 id="sentinel实现的功能">Sentinel实现的功能</h2>
<p>要想完成以上的故障转移任务，sentinel节点必须要具有以下几个功能才行</p>
<ol>
<li>监控：Sentinel节点会定期检测redis主节点以及其余的sentinel节点</li>
<li>通知：通知应用方修改最新的mater节点信息</li>
<li>主节点故障转移：实现从节点晋升为主节点</li>
<li>配置提供者：Redis Sentinel客户端中可以获取到主节点相关的信息</li>
</ol>
<blockquote>
<p>为什么sentinel节点要有多个？</p>
<ul>
<li>防止对主节点故障产生误判</li>
<li>防止sentinel节点的单点故障</li>
</ul>
</blockquote>
<h2 id="部署">部署</h2>
<p>先配置一个主从结构的集群，在此基础上配置哨兵节点，配置文件可以使用src目录下默认的sentinel.conf文件，不同节点的配置文件将端口修改一下。<br>
启动方式：</p>
<ol>
<li>使用redis-sentinel命令</li>
</ol>
<pre><code class="language-java">redis-sentinel redis-sentinel-23679.conf
</code></pre>
<ol start="2">
<li>redis-server 命令外加--sentinel 参数</li>
</ol>
<pre><code class="language-java">redis-server redis-sentinel-23679.cconf --sentinel
</code></pre>
<ol start="3">
<li>使用info Sentinel查看配置详情</li>
</ol>
<blockquote>
<p>部署成功之后sentinel对应节点的配置文件会出现一些变化，parallel-syncs、failover-timeout配置参数，其次还会新增sentinel known-replica(从节点)、sentinel known-sentinel(其它sentinel节点)等。</p>
</blockquote>
<h2 id="配置解析">配置解析</h2>
<pre><code class="language-java">sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;
</code></pre>
<p>ip和port表示主节点的地址，quorum和sentinel选举有关，在进行故障转移时会选举出一个leader进行故障转移，选举的算法为raft，quorum代表的是节点得到的票数只要大于quorum就会被选举为leader，但是quorum一般要大于半数。</p>
<pre><code class="language-java">sentinel down-after-milliseconds &lt;master-name&gt; &lt;times&gt;
</code></pre>
<p>这个代表的是sentinel leader节点发送给follower节点以及redis主从节点的超时时间，如果超过这个时间则判断该节点不可达。times设置越大应用的延迟越高，设置的过小有可能会造成节点不可达误判。</p>
<pre><code class="language-java">sentinel parallel-syncs &lt;master-name&gt; &lt;nums&gt;
</code></pre>
<p>表示选出新的主节点之后，允许多少个从节点同时进行复制操作，虽然复制操作时会fork出一个子进行程不会阻塞redis服务，但是会主节点所在机器的IO以及网络资源。</p>
<pre><code class="language-java">sentinel failover-timeout
</code></pre>
<p>有些复杂，暂时不做了解</p>
<pre><code class="language-java">sentinel auth-pass &lt;master-name&gt; &lt;password&gt;
</code></pre>
<p>如果主节点设置了requirepass参数配置，那么在部署哨兵服务的时候也要在配置上加上相关的权限校验配置。</p>
<pre><code class="language-java">sentinel notification &lt;master-name&gt; &lt;script-path&gt;
// 脚本demo
#!/bin/sh
#获取所有参数
msg=$*
# 报警脚本或者接口，将msg作为参数
exit 0
</code></pre>
<p>在故障转移期间，当出现警告级别的事时（客官下线，主管下线）会触发相应的脚本，执行脚本时会传递相应的参数信息，这些参数信息可以用来发送邮件通知开发人员。</p>
<pre><code class="language-java">sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;
// 脚本demo
#!/bin/sh
#获取所有参数
msg=$*
# 报警脚本或者接口，将msg作为参数
exit 0
</code></pre>
<p>和notification脚本触发时间有些区别，该脚本是在故障转移成功之后触发。</p>
<blockquote>
<p>关于notification和reconfig脚本限制条件</p>
<ul>
<li>可执行权限，即使用chmod 777修改权限</li>
<li>必须是shell脚本，即包含shell脚本头(#!/bin/sh)</li>
<li>脚本最大执行不可以超过60s，如果超过了就会被kill</li>
<li>如果redis sentinel节点过多，不建议使用脚本的方式进行通知</li>
<li>exit 0正常退出，exit 1脚本稍后重试，exit 2(&gt;=2)不会重试</li>
</ul>
</blockquote>
<h2 id="多节点监控">多节点监控</h2>
<p>这里是指如何使用sentinel监控多个redis主从复制集群，在介绍上面配置的时候，所有的配置都有一个master-name参数，如果想要监控多个集群，那么只需要将所有监控命令重新在一个配置文件中再写一遍，用master-name区分。</p>
<h2 id="客户端">客户端</h2>
<p>如果使用了哨兵模式的集群，那么对应的客户端也需要做调整，传统的jedis使用方式就已经不支持了需要被替换。具体的使用方式不会介绍，内容太多了不方便记忆，而且使用方式内容和redis的原理性的内容稍微有点不一样，后面单独记录在项目中怎么使用redis-sentinel集群模式。</p>
<h2 id="sentinel实现原理">sentinel实现原理</h2>
<h3 id="定时监控">定时监控</h3>
<ol>
<li>10秒<br>
每隔10秒，每个sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构。</li>
</ol>
<blockquote>
<p>这就是为什么在配置sentinel节点的时候不需要添加从节点的信息了，对主节点使用info命令会返回主从复制的结构信息。</p>
</blockquote>
<ol start="2">
<li>2秒<br>
每个sentinel节点（不包含redis服务节点）每隔两秒向redis数据节点上的_sentinel_:hello频道发送该sentinel节点对于主节点的判断以及当前sentinel节点的信息，并且每个sentinel还会订阅该频道来了解其他节点对于主节点的判断。主要作用：</li>
</ol>
<ul>
<li>发现新的sentinel节点，将自己的信息保存在_sentinel_:hello频道上，共享给其他sentinel节点</li>
<li>sentinel交换主节点的状态，作为后面客官下线以及领导者选举的依据，从而使节点不可达的健全性得到保障。</li>
</ul>
<blockquote>
<p>这段完全摘自《Redis开发与运维》第九章5小节，自己总结的实在是无法直视，索性直接搬过来。之前在实践redis sentinel集群模式的时候，发现sentinel配置文件中并没有配置几个节点关联起来监控一个redis集群，但是在启动之后，却发现redis集群可以被一个sentinel集群节点监控，当时自己就比较懵，我想此处应该就可以解决当时的困扰。</p>
</blockquote>
<ol start="3">
<li>1秒<br>
1秒的定时监控主要是用来做心跳检测的，sentinel节点每隔一秒钟会向所有节点（主从节点，其他sentinel节点）发送一次心跳。</li>
</ol>
<p><strong>redis sentinel监控图</strong><br>
<img src="https://hsxyhao.github.io/post-images/1574844918230.png" alt=""></p>
<blockquote>
<p>本来准备摘自《Redis开发与运维》上的图，但是发现三张图有些占地方，所以就自己画了张图，由于画图软件的原因有两个地方画不出来就没有弄了，不过不影响整体。虽然有些复杂但是如果把这个屡清楚了三个定时任务具体的功能也就清楚了。</p>
</blockquote>
<h3 id="主客观下线">主/客观下线</h3>
<p><strong>主观下线</strong><br>
当sentinel节点向redis服务节点发送ping心跳时，在down-after-milliseconds内服务没有回复的话就会被当前sentinel节点作失败判定，这个过程称为主观下线。<br>
<strong>客观下线</strong><br>
当被判定的节点是主节点的时候，那么该sentinel节点就会向其他节点询问主节点的状态，如果超过quorum个节点都判定为下线，那么就会做出客观下线的决定。</p>
<blockquote>
<p>向其他sentinel节点询问master节点的状况使用的是sentine is-master-down-by-addr命令，这里不做介绍。</p>
</blockquote>
<h3 id="领导选举">领导选举</h3>
<p>当对master节点做出客观下线后，不会立马进行故障转移操作，首先会在所有的sentinel节点中选出一个leader来进行故障转移操作。通过raft算法选举出leader节点，关于raft算法书中介绍的不是很详细，这里提供两个资料帮助理解raft算法。</p>
<ul>
<li><a href="http://thesecretlivesofdata.com/raft/">raft算法动画演示</a></li>
<li><a href="https://www.bilibili.com/video/av61558449/">b站白话讲解raft共识算法</a></li>
</ul>
<h3 id="故障转移">故障转移</h3>
<p>在选出leader节点之后就会进行故障转移操作，故障转移操作也很简单，在进行转移的时候对从节点的信息做一些简单的判断，过滤出最优从节点晋升。具体过程如下：<br>
<img src="https://hsxyhao.github.io/post-images/1574845720018.png" alt=""></p>
<ol>
<li>选择出新的主节点<br>
1). 过滤出所有不健康的节点(主观下线、断线)，5秒内没有回复过sentinel节点，以及与主节点失联超过down-after-milliseconds * 10秒。<br>
2). 判断有没有优先级高的从节点，即在配置文件中配置slave-priority属性的节点。<br>
3). 选择复制偏移量最大的节点，即数据最接近主节点的从节点。<br>
4). 选择runid最小的从节点(?)</li>
<li>对选择出来的从节点执行slaveof no one命令，和之前的手动操作类似。</li>
<li>sentinel节点会向其余的从节点发送命令，成为新主节点的从节点。</li>
<li>持续关注已经挂掉的主节点，一旦联系上，就将他变为新的主节点的从节点。</li>
</ol>
<h1 id="redis-cluster">Redis Cluster</h1>
<p>redis cluster可以理解为是一种水平扩展的方式，将数据分散在多个节点上，解决单机内存瓶颈限制。</p>
<h2 id="数据分布">数据分布</h2>
<p>在分布式缓存中，需要怎样将数据存储在多个节点中，并且读取时还能正常获取到对应的值？一般有以下方法来解决该问题，节点取余算法、一致性哈希算法以及redis使用的虚拟槽分区算法。</p>
<h3 id="算法介绍">算法介绍</h3>
<ol>
<li>节点取余分区<br>
节点取余算法就是对其key进行hash，得到hash值后对其进行服务节点数取模，得出的值便是对应的服务器位置。</li>
</ol>
<p>优点：</p>
<ul>
<li>易理解、便实现</li>
</ul>
<p>缺点：</p>
<ul>
<li>无法支持节点伸缩，即加机器和减机器</li>
</ul>
<ol start="2">
<li>一致性哈希分区<br>
首先抽象出一个哈希环，就是将一个环N（0~2<sup>32</sup>）份，将key哈希取值后的值顺时针映射到哈希环上的点。</li>
</ol>
<blockquote>
<p>为什么要顺时针映射，hash(key)的值不一定会刚好落在哈希环的节点上，这里的节点即数据服务节点，这时需要找到最近的一个数据节点，其实不论顺时针还是逆时针都可以，但是必须要统一，否则在查询的时候就会获取不到数据。</p>
</blockquote>
<p>优点：</p>
<ul>
<li>在只影响少量数据的情况下支持节点伸缩</li>
</ul>
<p>缺点：</p>
<ul>
<li>实现起来稍微麻烦一点</li>
<li>当节点数过少时，进行节点伸缩还是会影响到大部分数据</li>
</ul>
<ol start="3">
<li>虚拟槽分区<br>
将数据和节点通过槽进行解耦，抽象出一个具有16384个槽位的点，并且每个数据服务节点均分这些槽的管理权，hash(key)的值先通过虚拟槽的映射，然后找到对应的存储数据节点。</li>
</ol>
<p>优点：</p>
<ul>
<li>支持节点伸缩</li>
<li>通过解耦的方法降低了节点伸缩的难度</li>
</ul>
<p>缺点：</p>
<ul>
<li>不支持部分redis命令</li>
</ul>
<h2 id="搭建集群">搭建集群</h2>
<p>使用redis命令手动搭建一下集群，体会一下吐血的感受😫，搭建一个简单的小集群，只需要启动6个数据服务节点，不需要太多，不过有几点要注意。下面将展示搭建集群中用到的命令以及注意点的地方：<br>
命令：</p>
<pre><code class="language-java">cluster info
</code></pre>
<p>在redis客户端中使用这个命令可以查看到当前集群的信息，该命令只能查看到客户端连接集群节点信息，其他节点不能查看</p>
<pre><code class="language-java">cluster meet {host} {ip}
</code></pre>
<p>节点握手，使用该命令可以将一个新节点添加到集群中</p>
<pre><code class="language-java">cluster nodes
</code></pre>
<p>查看整个集群的拓扑信息，可以在输出的信息中了解到整个集群的节点信息、主从角色信息以及虚拟槽位点</p>
<pre><code class="language-java">cluster replicate nodeId
</code></pre>
<p>在集群中一般每个节点都会有一个从节点，主要是防止单点故障，使用该命令可以是当前节点与指定nodeId的节点建立主从关系，当前节点为从节点。当前节点需要已经添加到集群环境中。</p>
<pre><code class="language-java">redis-cli -h {host} -p {port} cluster addslots {0..16838}
</code></pre>
<p>在建立好集群关系后，还要为每个客户端分配槽，这里只对集群中主节点进行分配，只有当<strong>分配完16383</strong>个槽位之后集群才会处于上线状态。{a..b}为批量添加，即将a~b个槽位添加到节点中，且为闭区间，删除槽位可以使用delslots命令。</p>
<pre><code class="language-java">cluster forget nodeId
</code></pre>
<p>将节点移除集群环境，一般在集群下线之后会将使用该命令退出集群。</p>
<pre><code class="language-java">cluster keyslot key
</code></pre>
<p>计算出当前key的槽位，在集群环境中添加数据只有key属于那个槽位才能添加到节点中，否则会出现MODED错误信息。</p>
<blockquote>
<p>除了手动搭建节点，还可以使用官方提供的工具包搭建，但是要安装ruby环境，所以这里就不多做记录。</p>
</blockquote>
<p>注意：</p>
<ol>
<li>所有槽点都需要分配完才能进行读写</li>
<li>在本机搭建集群的时候最好是将所有的关于集群的配置文件烦放在一个目录下，方便管理</li>
<li>搭建好集群后，可以添加点数据到集群中，但是如果添加的数据，经过计算不属于当前节点是添加不进去的，会提示一个MOVED 10850 127.0.0.1:6380类似的错误，表示这个数据的槽位是10850，属于6380节点</li>
</ol>
<p>配置:</p>
<pre><code class="language-java">port 6380
pidfile /var/run/redis_6380.pid
logfile &quot;6380.log&quot;
dbfilename dump-6379.rdb
cluster-enabled yes
cluster-config-file nodes-6380.conf
cluster-node-timeout 15000
</code></pre>
<blockquote>
<p>一般集群实在多机器上部署的，但是我在测试的时候实在本机部署的，所以会增加一写关于端口的配置</p>
</blockquote>
<h2 id="节点通信">节点通信</h2>
<p>redis分布式集群中会通过维护节点元数据信息来保证集群的可用性，常见的元数据维护方式有集中式和P2P两种，redis采用的是后者，以及基于Gossip协议实现节点通信。</p>
<h2 id="集群伸缩">集群伸缩</h2>
<blockquote>
<p>暂时不做学习记录，不知道要记录哪些内容，感觉都是命令操作。</p>
</blockquote>
<h2 id="请求路由">请求路由</h2>
<ol>
<li>
<p>请求重定向（MOVED）<br>
在redis cluster集群环境中，如果将一个数据添加到集群中出现了MOVED错误提示，则表示当前节点不接受该数据，需要将数据添加到对应槽的节点中，这个过程称为请求重定向，在使用redis-cli启动客户端的时候，可以添加-c参数表示开启请求重定向，默认的客户端是不支持的。</p>
</li>
<li>
<p>hash_tag<br>
槽位是根据CRC16函数计算出来的，但是计算的内容并不是整个key，只计算有效内容。有效内容是通过{}包含起来的，这部分内容叫做hash_tag，可以使用hash_tag来进行优化，比如涉及到类似mget这种命令的，一次性获取多个key，但是一般多个key是在多个节点上的，mget是不支持这种场景的，使用hash_tag可以保证将多个key映射到同一个槽中。</p>
</li>
<li>
<p>ASK重定向<br>
ASK重定向是指发生在槽迁移的过程中，槽中的数据还没有迁移完成，数据一部分在源节点中，一部分在目标节点中。ASK重定向时客户端的命令流程：</p>
</li>
<li>
<p>client根据本地slots缓存发送命令到source节点，如果存在则直接执行命令发挥结果给客户端。</p>
</li>
<li>
<p>如果此时键不存在source节点，则会向客户端响应ASK异常信息。</p>
</li>
</ol>
<blockquote>
<p>(error) ASK {slot} {targetIP}:{targetPort}</p>
</blockquote>
<ol start="3">
<li>client从异常提示新提取出节点关键信息，发送asking名到目标节点，如果key存在则返回数据，否则返回不存在信息</li>
</ol>
<blockquote>
<p>之所以命名为ASK重定向，大概就取自asking这个命令吧</p>
</blockquote>
<p>目前对于客户端的重定向分为ASK重定向和MOVED重定向，但是两种重定向在slots缓存上有着本质的区别，ASK重定向不会更新本地的slots缓存，MOVED则会。ASK只是零时的重定向，不确定具体什么时候完成所以根本不需要更新slots缓存。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis复制]]></title>
        <id>https://hsxyhao.github.io/post/redis-copy</id>
        <link href="https://hsxyhao.github.io/post/redis-copy">
        </link>
        <updated>2019-11-19T08:19:22.000Z</updated>
        <summary type="html"><![CDATA[<p>什么是redis的复制，为什么要有复制功能，全量复制有什么问题，部分复制又解决了哪些问题。</p>
]]></summary>
        <content type="html"><![CDATA[<p>什么是redis的复制，为什么要有复制功能，全量复制有什么问题，部分复制又解决了哪些问题。</p>
<!-- more -->
<p>复制就是将redis节点中的数据复制完同步到其他节点中，在redis中参与复制一般有主节点(master)以及从节点(slave)，将数据从主节点复制到从节点，并且复制的方式是单向的，不能逆向复制，在建立复制关系之后主节点的数据会同步到从节点直到解除主从关系。不论是哨兵模式还是redis集群都是在复制的基础上完成的。<br>
记忆点</p>
<ol>
<li>使用方式：建立、断开复制、安全性、只读性</li>
<li>适用场景：哨兵、集群</li>
<li>复制原理：建立复制、全量复制、部分复制、心跳</li>
<li>常见问题：读写分离、数据不一致、避免全量复制</li>
</ol>
<h1 id="使用方式">使用方式</h1>
<ol>
<li>建立复制<br>
将具有复制关系的两个redis的节点一个称为master节点，另一个称为salve节点。主节点可以拥有多个从节点，从节点主能拥有一个主节点。<br>
建立连接方式:
<ul>
<li>配置文件：在redis从节点的配置文件中添加saveof ${masterHost} ${masterPort}配置</li>
<li>启动命令：在redis启动命令中加入 --saveof ${masterHost} ${masterPort}命令</li>
<li>运行时命令：在redis运行时直接使用 salveof ${masterHost} ${masterPort}命令</li>
</ul>
</li>
<li>断开复制<br>
在从节点中执行salve no one，断开复制不会清除之前同步成功的数据。</li>
<li>切换主节点<br>
在一个已经有主节点的从节点中执行slaveof ${newHost} ${newPort}就会切换到新的节点，但是之前同步的数据会被清空掉，这个和断开复制有点区别。</li>
<li>安全性<br>
在建立主从复制关系的时候，可以考虑数据的重要性，决定是否需要对主节点添加requirepass配置，这样在从节点建立复制关系的时候就会需要输入一个密码masterauth，这样的话可以提高数据的安全性。</li>
<li>只读性<br>
在默认的情况下从节点的数据是只读的，是不允许修改数据的，可以通过修改salve-read-only配置修改从节点的读写模式，但是这样会导致从节点和主节点数据不一致，不建议试用。</li>
</ol>
<h1 id="复制拓扑结构">复制拓扑结构</h1>
<ul>
<li>一主一从：可以用来解决单点故障问题，并且当写命令并发量大且开启AOF持久化时，可以将AOF持久化的放在从节点上。但是由于主节点没有开启AOF，所以在重启后数据会是空的，这个时候从节点如果同步主节点，会将之前的数据清洗掉，所以安全的做法是从节点先断开主从复制。</li>
<li>一主多从：又被称为星状结构，适用于读写分离的场景。建立复制连接之后，除了一开始的数据同步，在后期还会进行实时的写命令同步，这样如果从节点过多，并且写并发量比较大的话，那么会造成主节点的性能严重降低，还会增加网络带宽。</li>
<li>树状结构：可以理解为是对星状结构的优化，可以有效降低主节点负载，并且减少主节点同步的数目。</li>
</ul>
<h1 id="建立复制流程">建立复制流程</h1>
<ol>
<li>保存主节点信息<br>
执行salveof命令后从节点不会里面同步数据，只会先保存主节点的信息。从节点会在后台维护一个定时任务，正在的连接会交由定时任务执行，这个时候在从节点执行info replication命令可以查看到复制任务的进展。</li>
<li>主从建立socket连接<br>
在发现有新节点接入时，从节点会通过内部维护的每秒定时任务建立一个socket连接，如果没有第一次没有建立成功，后面会继续无限次重试，直到建立连接成功或者使用salve no one命令取消复制。</li>
<li>发送ping命令<br>
建立连接成功之后从节点会发送ping命令用来检测是否建立的套接字是否可用以及主节点是否可以接受处理命令，如果中间没有接收到主节点响应的pong命令，那么会断开复制，在交由定时任务后面重试连接。</li>
<li>权限验证<br>
在校验完连接之后，如果主检点设置了requirepass配置，那么会对权限进行校验，这个时候从节点需要配置masterauth配置校验信息。如果没有通过校验也会断开复制，后面再继续重新发起复制流程。</li>
<li>同步数据集<br>
权限校验完之后，会同步主节点的数据，redis 2.8版本之前会全部一次性同步所有数据，在2.8之后psync命令同步数据，这个新命令会带有一种类似断点续传的功能，毕竟数据量大的情况下，全部重传会非常消耗性能。</li>
<li>命令持续复制<br>
数据同步完之后，主节点还会把写命令持续同步给所有节点（这里会有网络消耗，所以在星状结构中从节点过多，会降低主节点性能），保证主从的数据一致性。</li>
</ol>
<h1 id="数据同步">数据同步</h1>
<p>在redis2.8之前使用的sync同步命令是将所有数据全部复制，如果之前复制到一半，后期重新连接上开始复制，又会重新复制所有数据，其实可以不用这样，因为之前已经复制了一部分，所以重试连接后的复制只要从断开的部分开始就行了。这就是psync新命令的效果。</p>
<ol>
<li>全量复制<br>
一般发生在第一次复制连接，早期的版本全部是全量复制，这样操作在数据量大并且发生网络闪断时会严重拉低主节点的性能。</li>
<li>部分复制<br>
2.8版本后期添加的，相对于全量复制，部分复制在发生网络断开重连后不会复制全部数据，会接着没有复制完的数据继续复制任务。</li>
</ol>
<h1 id="psync命令">psync命令</h1>
<p>在数据同步的时候经常会遇到需要查看复制信息以及进度的情况，这个时候可以使用info replication命令查看详情。还有一种情况就是关于runId的，当遇到需要调优的时候，会修改一些内存相关的配置，这时如果重启了redis服务，那么runId就会改变，所以要考虑到在不关服务的情况下重启，可以使用debug reload命令达到效果。</p>
<h2 id="版本差异">版本差异</h2>
<p>redis在2.8之前使用的sync命令，全部全量复制，2.8~4.0的时候使用的是psync1命令，这个版本加上了部分复制，在4.0版本的时候使用了psync2命令，增加了重启部分复制功能以及混合持久化等。psync2命令后面找到资料后在继续记录，这里的psync1和psync2中的1和2都是版本，真实的命令还是psync。</p>
<h2 id="相关知识点">相关知识点</h2>
<ol>
<li>主从节点各自复制偏移量<br>
主节点会将自身同步的数据量记录下来，从节点也会维护一个自身已经接收成功的数据量，并且还会每秒向主节点同步一次数据，主节点也需要记录下来，可以根据主节点记录的从节点偏移量以及从节点自身记录的偏移量判断同步的数据是否一致。</li>
<li>主节点复制积压缓冲区<br>
在主节点进行数据同步的时候，需要接收客户端的写命令，写命令除了同步给从节点以外还会写入到复制积压缓冲区中，主要用来做写命令的备份。在从节点出现网络断开重连时进行数据修补。</li>
<li>主节点运行id<br>
一个40位的16进制字符串，用来标志唯一的运行时redis服务，注意是运行时，如果redis重启之后id会改变，从节点会从新进行全量复制。查看runid的命令，info server</li>
</ol>
<blockquote>
<p>如果使用ip:port标志唯一的redis服务，如果当前redis重启之后并且主节点的数据集已经更改，那么再从之前的位置复制的话，主从数据就不一致了。</p>
</blockquote>
<h1 id="psync流程">psync流程</h1>
<h2 id="前期">前期</h2>
<figure data-type="image" tabindex="1"><img src="https://hsxyhao.github.io/post-images/1574410766776.png" alt=""></figure>
<ol>
<li>从节点发送psync命令到主节点，runid是主节点的，在建立复制关系时保存下来的。offset是偏移量，如果是第一次复制，则为-1，否则是从节点保存的复制偏移量。</li>
<li>主节点根据psync的两个参数作出相应，如果runid不一致，则直接进行全量复制，否则会进行部分复制。</li>
</ol>
<ul>
<li>全量复制户响应：+FULLRESYNC</li>
<li>部分复制：+CONTINUE</li>
<li>错误响应：+ERR，无法识别psync命令，从节点将发送旧版本的sync命令触发全量复制</li>
</ul>
<h2 id="全量复制">全量复制</h2>
<p>当从节点收到来自主节点的全量复制的响应时，会进行全量复制。<br>
<img src="https://hsxyhao.github.io/post-images/1574413814260.png" alt=""></p>
<ol>
<li>1)、2)步骤是psync数据同步前期，这个阶段是来判断进行全量复制还是部分复制</li>
<li>3)从节点接受到来自主节点的全量复制响应，会保存主节点的runId以及offset</li>
<li>4)主节点开始执行bgsave命令，这个bgsave会引起RDB方式的持久化，持久化完成之后会发送给从节点</li>
<li>5)主节点将完成的RDB文件发送给从节点</li>
<li>6)发送完RDB文件之后，还会将复制积压缓冲区中的写命令同步给从节点。</li>
<li>7)从节点清空自身的数据</li>
<li>8)加载接收到的RDB文件。</li>
<li>9)从节点加载完RDB文件之后，如果当前节点开启的AOF持久化，那么会继续执行bgrewriteaof命令进行aof持久化。</li>
</ol>
<h3 id="全量复制问题思考">全量复制问题思考</h3>
<ol>
<li>主节点数据量过大，同步时间过长，导致全量同步失败怎么办？<br>
在主节点同步的过程中如果RDB文件太大（G级别），repl-timeout决定复制的时间，如果超过这个时间则全量复制失败。</li>
<li>什么是无盘复制？<br>
为了降低主节点的磁盘写入开销，可以将redis生成的RDB文件不保存在磁盘中，直接发送给从节点，不过这个功能目前还不太完善，不建议线上使用，具体什么时候稳定，等待官方最新消息。</li>
<li>写命令高并发场景？<br>
在写命令比较频繁的场景：由于主节点在进行全量复制的时候依旧响应来自客户端的写命令，如果这个时候复制积压缓冲区的溢出，则主节点会关闭客户端连接，全量同步失败，建议将clint-output-buffer-limit设置大一点。</li>
<li>读写分离场景发生全量复制怎么办？<br>
读写分离场景，如果出现了全量复制的时间过长，从节点正在响应客户端的读请求，但是由于同步未完成，这个时候拿到的数据可能是过期的甚至是错误的。关于这点，redis提供了一个slave-serve-stale-data参数，这个参数代表的意思就是在复制期间从节点是否可以进行读请求响应，如果业务对于数据的准确性要求过高，那么可以将这个参数设置为no，这个时候从节点对于info和slaveof命令之外其他命令只会响应SYNC with master in process信息。</li>
<li>全量复制期间有哪些比较耗时的操作？
<ul>
<li>主节点bgsave</li>
<li>传输RDB文件</li>
<li>从节点清空阶段</li>
<li>从节点加载RDB阶段</li>
<li>AOF重写阶段（如果从节点开启了AOF重写）</li>
</ul>
</li>
</ol>
<h2 id="部分复制">部分复制</h2>
<p>从上面可以得知一个全量复制的成本是相当的高的，所以redis在2.8版本之后对齐做了优化，出现了部分辅助功能，就是百度、迅雷等常用软件的一种断点续传的功能。在进行全量复制的过程中如果出现了网络闪断或者命令丢失等情况时，从节点会要求主节点补发丢失的命令数据，如果主节点的复制积压缓冲区存在这部分数据则直接发送给从节点。<br>
<img src="https://hsxyhao.github.io/post-images/1574418539238.png" alt=""></p>
<ol>
<li>1)主从之间网络出现中断</li>
<li>2)主节点依旧响应请求，这时的写命令会写入到复制积压缓冲区中</li>
<li>3)当主节点网络恢复后，从节点会在再次连上主节点</li>
<li>4)主从连接成功后，从节点会将断开之前自身保存的复制偏移量以及runId结合psync命令发送给主节点。</li>
<li>5)主节点首先判断runId是否一致，不一致的话直接进行全量复制，如果一致，再判断偏移量是否在复制缓冲区内，如果存在才会进行部分复制，此时会向从节点响应CONTINNUE命令。</li>
<li>6)主节点会根据偏移量向从节点发送部分数据</li>
</ol>
<blockquote>
<p>这里在看《redis开发与运维》这本书的时候，对于复制积压缓冲区还是不太明白，它到底是用来存储什么的，一开始我理解的是复制连接阶段的主节点写入命令，但是在部分复制章节看到，主节点会根据从节点的偏移量是否在复制积压缓冲区内来决定是否部分复制。那么就有个问题如果全量复制的时候发生网络中断了，那么从节点再连上之后是进行部分复制吗？如果是部分复制那之前的数据肯定不在缓冲区中啊！还是说部分复制只会发生在全量复制完成之后的时间段，如果连接断开则会丢失一段时间的写命令数据，这个时候只要把写命令数据同步了，就算部分复制了？这点有待深入了解后期跟新。（后面全量复制场景已经得到找到问题的答案了😅）</p>
</blockquote>
<h1 id="心跳">心跳</h1>
<p>redis通过心跳维护主从节点之间的长连接，主节点默认每10秒(repl-ping-slave-period控制频率)发送ping命令，判断从节点的存活性和连接状态。从节点在主线程中每隔1秒发送replconf ack offset命令，给主节点上报当前的偏移量。<br>
<img src="https://hsxyhao.github.io/post-images/1574489105257.png" alt=""></p>
<h2 id="考点">考点</h2>
<ol>
<li>心跳机制中从节点每次上报自身的偏移量有什么作用?</li>
</ol>
<ul>
<li>实时监测主从节点网络状态，上报自身复制偏移量，检查复制数据是否丢失，如果从节点数据丢失，再从主节点的缓冲区中拉取数据，保证数据一致性。（如果偏移量不在复制积压缓冲区范围内怎么办？）</li>
<li>实现保证从节点的数量和延迟性功能(min-slaves-to-write、min-slaves-max-lag)。</li>
</ul>
<h1 id="全量复制场景">全量复制场景</h1>
<ol>
<li>第一次建立复制关系（无法避免）</li>
<li>运行id不一致</li>
</ol>
<blockquote>
<p>由于主节点故障重启导致的runId不一致，建议在主节点故障时自动将从节点晋升主节点</p>
</blockquote>
<ol start="3">
<li>复制积压缓冲区内存不足</li>
</ol>
<blockquote>
<p>主从节点的网络发生闪断，当从节点重连成功后就会进行部分复制，但是如果在写并发量特别大或者重连时间过长导致复制积压缓冲区内存不足，那么这个时候主节点根据从节点发送来的偏移量不在缓冲区范围内，这个时候就无法进行部分复制，会退化成全量复制，这个时候就需要对缓冲区的大小进行合适的设置。当然在第一个全量的复制的时候如果复制时间特别长也导致缓冲区不足那么复制也会中断。</p>
</blockquote>
<h1 id="复制风暴">复制风暴</h1>
<p>当一个主节点有多个从节点(星状拓扑)，如果一旦主节点故障，重启成功后，那么会有多个从节点进行全量复制，这个会导致主节点发送RDB文件到多个从节点，严重降低主节点的性能，建议使用树状结构代替星状，减去主节点负担。还有个场景就是多个主节点部署在同一台机器上，这样也会造成单机复制风暴，就是主节点所在的服务器出现性能瓶颈，对于这种场景建议使用多机部署方案提高性能。</p>
<h1 id="总结">总结</h1>
<p>关于复制主要了解一下复制的每个步骤的具体操作，以及全量复制和部分复制相关的内容</p>
<h1 id="参考文档">参考文档</h1>
<p>《Redis开发与运维》</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis 持久化]]></title>
        <id>https://hsxyhao.github.io/post/redis-chi-jiu-hua</id>
        <link href="https://hsxyhao.github.io/post/redis-chi-jiu-hua">
        </link>
        <updated>2019-11-16T09:04:43.000Z</updated>
        <summary type="html"><![CDATA[<p>持久化有哪几种方式，各有什么问题。每种持久化的流程是什么样的，AOF重写是什么机制，解决了什么问题，fork底层函数，COW机制。</p>
]]></summary>
        <content type="html"><![CDATA[<p>持久化有哪几种方式，各有什么问题。每种持久化的流程是什么样的，AOF重写是什么机制，解决了什么问题，fork底层函数，COW机制。</p>
<!-- more -->
<h1 id="面试">面试</h1>
<p>在面试的时候如果被问到Redis持久化的时候，怎么回答比较好？我想从以下几个角度展开，一定会让面试官眼前一亮。</p>
<ul>
<li>RDB冷备份以及AOF热备份</li>
<li>fork函数</li>
<li>COW（Copy on write）写时复制机制</li>
<li>AOF命令重写</li>
</ul>
<h1 id="cow机制">COW机制</h1>
<blockquote>
<p>写入时复制（英语：Copy-on-write，简称COW）是一种计算机程序设计领域的优化策略。其核心思想是，如果有多个调用者（callers）同时请求相同资源（如内存或磁盘上的数据存储），他们会共同获取相同的指针指向相同的资源，直到某个调用者试图修改资源的内容时，系统才会真正复制一份专用副本（private copy）给该调用者，而其他调用者所见到的最初的资源仍然保持不变。这过程对其他的调用者都是透明的（transparently）。此作法主要的优点是如果调用者没有修改该资源，就不会有副本（private copy）被创建，因此多个调用者只是读取操作时可以共享同一份资源。</p>
</blockquote>
<p>上面一段话摘自<a href="https://zh.wikipedia.org/wiki/%E5%AF%AB%E5%85%A5%E6%99%82%E8%A4%87%E8%A3%BD">维基百科</a>，简单的理解就是在有多个进程请求同一个文件的时候，都会先持有这份文件，但是只有在程序试图去修改的时候，这个程序会先复制一份文件，后面的修改会基于复制的文件，不会改动源文件。这样其他的程序所持有的还是未改动的文件。</p>
<h1 id="rbd">RBD</h1>
<p>RBD是Redis持久化方式的一种，主要是基于COW机制实现的一种类似快照的持久化方式。在Redis运行中将所有的数据复制一份输出到磁盘上，其分为两种触发机制手动触发以及自动触发。</p>
<h2 id="触发机制">触发机制</h2>
<h3 id="1手动触发">1.手动触发</h3>
<p>手动触发主要依靠开发人员使用save以及bgsave命令来启动，save和bgsave主要区别在于save是阻塞式的，bgsave会fork一个子进程来进行持久化，除了在fork过程中会出现一小段时间的阻塞外，其余时间不会阻塞服务，在持久化完成之后会自动结束进行。</p>
<h3 id="2自动触发">2.自动触发</h3>
<p>除了手动触发外，还有自动触发机制，自动触发场景如下：</p>
<ul>
<li>开启save配置(save m n)，每m秒数据出现n次修改就会自动触发</li>
<li>从节点全量复制</li>
<li>执行debug reload重新加载redis</li>
<li>在没有开启AOF持久化时，执行shutdown命令</li>
</ul>
<h2 id="bgsave流程">bgsave流程</h2>
<p>bgsave命令首先会判断是否存在RBD或者AOF子进程，如果没有则创建，若存在则直接返回。紧接着父进程会fork一个子进程，fork这段时间会出现短时间阻塞，然后父进程继续响应客户端，子进程生成RBD文件，完成持久化之后通知父进程。<br>
<img src="https://hsxyhao.github.io/post-images/1573897466755.png" alt=""><br>
bgsave命令流程说明，图片摘自《Redis开发与运维》一书</p>
<h2 id="rbd文件">RBD文件</h2>
<p>RDB的保存于dir配置指定下的目录，除此之外还可以使用config set dir动态修改RDB文件的位置以及config set dbfilename动态修改RBD文件的名称，这个在线上环境的磁盘出现问题或者写满的时候有用。</p>
<h2 id="cow的运用">cow的运用</h2>
<p>fork出来的子进程需要对父进程的数据进程持久化，但是这个时候父进程会响应来自客户端的请求，对数据进行修改，如果此时出现了一个非常大的数据正在持久化，但是突然客户端来了一个删除命令，这个时候持久化就会失败。但是如果基于cow机制的话就可以避免这个问题，父进程修改的是复制出来的数据，子进程持久化的还是原来的数据没有被修改，不会受父进程的影响。</p>
<h2 id="rdb-优缺点">RDB 优缺点</h2>
<p>优点：</p>
<ul>
<li>RDB适合用来做冷备份，加载速度比AOF快</li>
</ul>
<p>缺点：</p>
<ul>
<li>RDB文件的版本有很多，版本之间互相不兼容</li>
<li>不适合实时备份，fork操作会很耗性能，与redis的高性能相违背</li>
</ul>
<h1 id="aof">AOF</h1>
<p>相对于RDB来说，AOF是可以进行实时(秒级)持久化的。比较适合用来做热备份，通过配置文件中的appendonly yes来开启，appendfilename为AOF持久化的文件名，默认为appendonly.aof。</p>
<h2 id="aof工作流程">AOF工作流程</h2>
<p>AOF持久化首先会将客户端请求的命令放入到AOF缓存中，然后根据磁盘的刷新策略写入到磁盘中，当AOF文件达到上限时，会进行AOF重写，对文件进行瘦身，最后在redis重启的时候重新加载下AOF文件即可。<br>
<img src="https://hsxyhao.github.io/post-images/1573900560042.png" alt=""></p>
<h3 id="命令写入过程">命令写入过程</h3>
<p>服务端接收到客户端按照RESP协议文本格式的命令后，会将其直接写入到aof缓存区内。使用aof缓存可以提高redis的性能，以及使用不同缓存区刷新策略，可以在性能和安全方面做出平衡。<br>
AOF刷新策略</p>
<ul>
<li>always 命令写入缓冲区后，调用fsync写入到磁盘上。即没接收到一条命令就写入到磁盘上。</li>
<li>everysec 命令写入缓冲区后，同步文件操作有专门线程每秒钟同步一次。(推荐使用)</li>
<li>no 同步操作由硬盘操作，同步周期最长为30s</li>
</ul>
<h2 id="重写机制">重写机制</h2>
<p>AOF文件随着命令不断被写入体积会越来越大，但是已经同步过的命令并不是所有的命令都是有效的，有的命令是可以被优化掉，这样可以减少AOF文件体积，还可以降低加载时间。</p>
<h3 id="优化场景">优化场景</h3>
<ul>
<li>内存中已经过期的数据不会被同步。</li>
<li>旧的AOF文件中无效的命令，del、hdel、srem等。</li>
<li>命令合并，将多条命令合并成一条指令。</li>
</ul>
<h3 id="aof重写触发机制">AOF重写触发机制</h3>
<p>手动触发：bgrewriteaof<br>
自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定，简单的理解就是当前文件大小大于重写最小值并且aof文件增长率大于设置的值。</p>
<blockquote>
<p>auto-aof-rewrite-min-size表示运行AOF重写时文件最小体积，默认为64MB，auto-aof-rewrite-percentage代表当前AOF文件空间(aof_current_size)和上一次重写后的文件空间占比。自动触发时机=aof_current_size&gt;auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size) / aof_base_size &gt;= auto-aof-rewrite-percentage</p>
</blockquote>
<h3 id="aof重写流程">AOF重写流程</h3>
<p>AOFfork的子进程只是用来重写已经存在AOF文件，AOF写入还是由父进程来完成。<br>
<img src="https://hsxyhao.github.io/post-images/1574070629984.png" alt=""><br>
1.执行AOF重写请求<br>
如果当前已经存在AOF重写任务，则当次请求不执行，如果已经有bgsave正在执行，则当前请求会等待该任务执行完成后启动。<br>
2.父进程fork一个子进程用来重写AOF文件，将客户端的命令<strong>同时</strong>保存到aof_buf以及aof_rewrite_buf中</p>
<ul>
<li>3.1 原有的AOF持久化操作会正常进行，保持从aof_buf中读取数据写入到旧的aof文件中。</li>
<li>3.2 同时会将命令写入到aof_rewrite_buf中，保证命令重写操作后的数据一致性。</li>
</ul>
<p>4.子进程的重写操作会根据内存快照进行重写，生成新的aof文件。<br>
5.1子进程完成重写之后会发给父进程发送一个完成信号，父进程会更新相关的统计数据</p>
<ul>
<li>5.2父进程把aof_rewrite_buf缓冲区的数据重写到新的aof文件中</li>
<li>5.3使用新的AOF文件替换老的AOF文件</li>
</ul>
<blockquote>
<p>体会：在AOF重写过程中会有aof_buf以及aof_rewrite_buf两个缓存区，第一个aof_buf缓存区主要的目的就是用来保持原有的AOF持久化的正常进行。第二个缓冲区aof_rewrite_buf缓冲区是保存在重写期间接收到的命令，一开始我在思考的时候不是很明白，aof_buf也会保存重写期间的数据，为什么还要在保存一份到rewrite的缓存区中？主要就是aof_buf是提供给持久化操作的，在重写操作完成之后是要将旧的文件替换掉的，所有这个时候需要将重写期间的命令单独保存下来，等重写完成之后再同步rewrite的数据，从而保证了AOF的连续性。</p>
</blockquote>
<h1 id="总结">总结</h1>
<p>这篇文章主要用来概括性记录下redis持久化操作所包含的知识点，大部分内容是我整合起来的。但是基本上都是加以自己的理解写出来的，没有直接CV，当然图片是我直接抄过来的。主要目的就是大概的记录下AOF涉及到的知识点，方便后期深入了解，以及回顾的时候可以有个快速的了解。</p>
<h1 id="参考文献">参考文献</h1>
<p><a href="https://book.douban.com/subject/26971561/">《Redis开发与运维》</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Redis入门知识点]]></title>
        <id>https://hsxyhao.github.io/post/rui-shi-jun-dao-redis</id>
        <link href="https://hsxyhao.github.io/post/rui-shi-jun-dao-redis">
        </link>
        <updated>2019-11-14T07:49:23.000Z</updated>
        <summary type="html"><![CDATA[<p>redis有哪些基础数据结构，什么是快速链表，什么是跳跃链表，使用redis特有的数据类型可以实现哪些有趣的功能。</p>
]]></summary>
        <content type="html"><![CDATA[<p>redis有哪些基础数据结构，什么是快速链表，什么是跳跃链表，使用redis特有的数据类型可以实现哪些有趣的功能。</p>
<!-- more -->
<blockquote>
<p>Redis is an open source (BSD licensed), in-memory data structure store, used as a database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs, geospatial indexes with radius queries and streams. Redis has built-in replication, Lua scripting, LRU eviction, transactions and different levels of on-disk persistence, and provides high availability via Redis Sentinel and automatic partitioning with Redis Cluster.</p>
</blockquote>
<p>上面一段话取自Redis官方的介绍，为什么要把它放在这里，我觉得这是介绍Redis最为标准的一段话，从用途、数据结构已经功能等多方面介绍，如果以后面试官叫你介绍下redis的话，我觉得可以直接把这段话背下来😌。至于为什么把Redis称为瑞士军刀，相信用过redis的人都会这么认为。</p>
<h1 id="redis-key">Redis key</h1>
<p>Redis密钥是二进制安全的，任何二进制序列的字符串都可以作为密钥，空字符串也是有效的键。虽然key的有效长度为512M，但是在日常开发中不建议把key的长度设置太长，或者过短，最友好的一种做法是将key和业务结合起来命名，一般推荐使用user:{id}这样的方式。</p>
<h1 id="数据类型"><a href="https://redis.io/topics/data-types-intro">数据类型</a></h1>
<p>从redis的官方介绍中就可以得出，redis的基础数据类型有五种，分别为：string，hash，list，set，以及zset。至于后面提到的hyperloglogs、geospatial、bitmaps的类型，有的是后面的版本增加的，有的是基础数据类型扩展来的。相对于其他的nosql数据库来说，redis的数据类型已经很充分了。redis内置的这些类型，对于学过java的同学可以使用java中的HashMap来辅助记忆，比如说string类型就是Map&lt;String,String&gt;,list类型就类比为Map&lt;String,List<String>&gt;，hash则为Map&lt;String,Map&lt;String,String&gt;&gt;。通过这样的辅助记忆，就可以很快的记住redis的数据类型，对于后期各种类型的命令使用也起到一定的帮助。从上面的类比中我们可以看到redis是一个key，value的数据存储系统，key都是字符串类型，value则对应redis着以上几种数据类型。</p>
<h2 id="1-string类型">1. string类型</h2>
<p>string类型，可以说是redis中使用到最多的一种类型了，开发中有很多开发人员把一些热点数据的序列化成json，存储到redis中，最后访问的时候后再取出来反序列化返回到客户端。<br>
<img src="https://hsxyhao.github.io/post-images/1573721308127.png" alt=""><br>
重点记忆：</p>
<ul>
<li>最大能存储512M的内容</li>
<li>value的值是可以修改的，内部采取的是一种预扩容机制来减少频繁的扩容，如图中所示，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。</li>
</ul>
<p>命令：</p>
<pre><code class="language-java">// 添加一个键值对
&gt; set key1 value1
OK
// 添加多个键值对，改名相当于多次使用set名，mset可以减少网络请求
&gt; mset key1 value1 key2 value2 
OK
// 当value是int类型的时候可以进行加减操作，超过signed long（Long.Max）则会报错
&gt; set counter 100
OK
&gt; incr counter
(integer) 101
&gt; incr counter
(integer) 102
&gt; incrby counter 50
(integer) 152
</code></pre>
<h2 id="2-list类型">2. list类型</h2>
<p>Redis中的list相当于java中的LinkedList，不是ArrayList，也就是说他是一个链表。结合*pop和*push命令可以实现队列或者栈这种数据结构。<br>
<img src="https://hsxyhao.github.io/post-images/1573722527155.gif" alt=""></p>
<h3 id="快速链表">快速链表</h3>
<p><img src="https://hsxyhao.github.io/post-images/1573801624670.png" alt=""><br>
准确的说list类型的底层实现是快速链表，普通链表在数据量量大的情况下性能是非常低的，所以需要对list进行优化。在列表开始数据量少的情况下，会直接申请一块<strong>连续</strong>的内存存储，这块内存的结构就是ziplist(压缩列表)，当数据量比较多的时候会切换成quicklist，就是多个ziplist结合成的链表。</p>
<h3 id="list扩展应用">list扩展应用</h3>
<ol>
<li>结合rpush以及lpop（或者lpush和rpop）可以实现redis版的队列，右进左出（或左进右出）。</li>
<li>使用rpush以及rpop（或者lpush和lpop）可以实现redis版的栈，右进右出（左进左出）。</li>
</ol>
<p>命令:</p>
<ul>
<li>ltrim [start_index, end_index]命令，会保留start_index和end_index之间的部分</li>
<li>lindex相当于链表的get方法，时间复杂度为O(n),index越大性能越低。</li>
</ul>
<pre><code class="language-java">&gt; rpush books python java golang
(integer) 3
&gt; lindex books 1  # O(n) 慎用
&quot;java&quot;
&gt; lrange books 0 -1  # 获取所有元素，O(n) 慎用
1) &quot;python&quot;
2) &quot;java&quot;
3) &quot;golang&quot;
&gt; ltrim books 1 -1 # O(n) 慎用
OK
&gt; lrange books 0 -1
1) &quot;java&quot;
2) &quot;golang&quot;
&gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负
OK
&gt; llen books
(integer) 0
</code></pre>
<h2 id="3-hash类型">3. hash类型</h2>
<p>hash类型可以类比成java中HashMap，一种键值对类型，只不过这里的key只能是string类型。</p>
<h3 id="rehash">rehash</h3>
<p>相信大多数java开发人员在面试的时候都会被问到rehash，这个过程在数据量大的时候是一个性能相当低的操作，而redis为了提高性能，就采取了另一种方式进行rehash——渐近式，就是在rehash的时候不立马进行rehash，保存一个新的hash结构的同时，旧的也保存下来，在后续的定时任务中，或者有hash操作的时候进行迁移，当数据迁移完成之后，旧的hash就会被新的取代。</p>
<h3 id="与string应用比较">与string应用比较</h3>
<p>hash也可以用来保存用户信息的类似操作，但是相对于string来说，hash可以保存一个用户的单个属性，在数据量以及请求非常大的情况下，获取单个属性相比较或者所有属性来说，更加节约网络流量，但是hash的存储结构消耗要高于string。</p>
<p>命令</p>
<pre><code class="language-java">&gt; hset books java &quot;think in java&quot;  # 命令行的字符串如果包含空格，要用引号括起来
(integer) 1
&gt; hset books golang &quot;concurrency in go&quot;
(integer) 1
&gt; hset books python &quot;python cookbook&quot;
(integer) 1
&gt; hgetall books  # entries()，key 和 value 间隔出现
1) &quot;java&quot;
2) &quot;think in java&quot;
3) &quot;golang&quot;
4) &quot;concurrency in go&quot;
5) &quot;python&quot;
6) &quot;python cookbook&quot;
&gt; hlen books
(integer) 3
&gt; hget books java
&quot;think in java&quot;
&gt; hset books golang &quot;learning go programming&quot;  # 因为是更新操作，所以返回 0
(integer) 0
&gt; hget books golang
&quot;learning go programming&quot;
&gt; hmset books java &quot;effective java&quot; python &quot;learning python&quot; golang &quot;modern golang programming&quot;  # 批量 set
OK
# 整形变量的自增操作
&gt; hincrby user-laoqian age 1
(integer) 30
</code></pre>
<h2 id="4-set类型">4. set类型</h2>
<p>同样的set类型可以类比为java中的HashSet，是一种键值对唯一的数据结构，大家都知道java中的HashSet是由HashMap“变异”的，相对于HashMap，HashSet的所有value都是Null。set具有自动去重的功能，可以保证set中的可以是唯一的。<br>
<img src="https://hsxyhao.github.io/post-images/1573804430835.gif" alt=""><br>
命令：</p>
<pre><code class="language-java">&gt; sadd books python
(integer) 1
&gt; sadd books python  #  重复
(integer) 0
&gt; sadd books java golang
(integer) 2
&gt; smembers books  # 注意顺序，和插入的并不一致，因为 set 是无序的
1) &quot;java&quot;
2) &quot;python&quot;
3) &quot;golang&quot;
&gt; sismember books java  # 查询某个 value 是否存在，相当于 contains(o)
(integer) 1
&gt; sismember books rust
(integer) 0
&gt; scard books  # 获取长度相当于 count()
(integer) 3
&gt; spop books  # 弹出一个
&quot;java&quot;
</code></pre>
<h2 id="5-zset有序集合">5. zset(有序集合)</h2>
<p>set是一个无序不重复集合，zset是一个有序的不重复集合，redis内部是通过跳跃链表来实现的。要想对一个链表排序，普通的链表肯定是不行的。需要对普通链表进行改进，改造后就是跳跃链表了。<br>
<img src="https://hsxyhao.github.io/post-images/1573807555093.png" alt=""><br>
上图就是跳跃链表的一个简化示意图，相信不熟悉的人看到这里肯定会懵，这个“跳跃”二字如何解释，在这里跳跃是指层与层之间的一个切换，不是元素和元素之间。层是代表高度词，所以用跳跃来形容也比较合适。</p>
<h1 id="最后">最后</h1>
<p>这里只是对Redis的基本数据类型进行一个简单记录，将所有重要的地方都记录下来，但是没有详细记录，在面试的时候如果聊到Redis，可以简单的做个大概介绍，后面再慢慢深入，后续的文章中会对文中的一些点进行详细的学习记录。本篇文章主要根据网上的资料进行总结，说不上复制，如果单纯的把别人的东西复制过来放在自己的博客上，行为上本身就是可耻的（未标明原著），其次在效果上也是微乎其微 。建议大家平时看过一些东西之后转换成自己的理解后记录下来，这样的话效果也会好很多🤓。</p>
<h1 id="相关文档">相关文档</h1>
<p><a href="https://redis.io/topics/data-types-intro">Redis官方文档</a><br>
<a href="https://juejin.im/book/5afc2e5f6fb9a07a9b362527">Redis 深度历险：核心原理与应用实践</a></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Gridea搭建个人博客]]></title>
        <id>https://hsxyhao.github.io/post/gridea-setup</id>
        <link href="https://hsxyhao.github.io/post/gridea-setup">
        </link>
        <updated>2019-11-13T05:47:44.000Z</updated>
        <summary type="html"><![CDATA[<p>使用Gridea搭建静态博客，记录踩坑血史🤓</p>
]]></summary>
        <content type="html"><![CDATA[<p>使用Gridea搭建静态博客，记录踩坑血史🤓</p>
<!-- more -->
<h2 id="搭建教程">搭建教程</h2>
<h3 id="1github相关配置">1.github相关配置</h3>
<p>创建github pages、token以及开通oauth认证。</p>
<ol>
<li>新建一个名为XXX.github.io的仓库，就是一个普通的github仓库只不过名字需要有一定的规则</li>
<li>在github右上角进入settings页面，在进入Developer settings页面
<ul>
<li>添加一个个人访问token，添加完之后立马复制保存一下，token是一次性可见的，后面在访问的时候就会消失，那个时候只能从新创建一个了。权限选择第一个repo就行了。<br>
<img src="https://hsxyhao.github.io/post-images/1573626367969.png" alt=""></li>
<li>然后再创建一个oauth app，后面开通评论会用到。<br>
<img src="https://hsxyhao.github.io/post-images/1573626568363.jpg" alt=""></li>
</ul>
</li>
</ol>
<h3 id="2安装gridea客户端">2.安装Gridea客户端</h3>
<p>把Gridea项目克隆到本地git clone https://github.com/getgridea/gridea，按照官方的命令启动客户端，这里要使用yarn命令，没有的话安装一下。</p>
<pre><code class="language-java"># Node version &gt; v10.0.0 is requied
$ git clone https://github.com/getgridea/gridea.git
$ cd gridea
$ yarn
$ yarn electron:serve
$ yarn electron:build
</code></pre>
<h3 id="3绑定github信息">3.绑定github信息</h3>
<p>将之前创建的token、仓库、域名等信息配置一下，配置好之后保存一下。<br>
<img src="https://hsxyhao.github.io/post-images/1573627331402.jpg" alt=""></p>
<h3 id="4添加gittalk评论">4.添加Gittalk评论</h3>
<p>开通评论，需要使用到oauth账号，填写好之后，保存一下。<br>
<img src="https://hsxyhao.github.io/post-images/1573627495172.png" alt=""></p>
<h3 id="5完结散花">5.完结散花🍂</h3>
<p>最后一步，点击左下角同步一下就可以了。如果同步出现问题，请移步到文章尾部，看看是否能帮助到你。</p>
<h2 id="帮助">帮助</h2>
<p>最后再补充一下搭建过程中遇到的问题，希望能帮助的你。</p>
<h3 id="踩坑">踩坑</h3>
<ol>
<li>在所有信息配置完之后，点击同步或者检测远程连接会出现失败的情况，如果你是第一次使用Gridea的话，那么需要将Gridea的output目录初始化为一个git仓库，然后添加远程的github地址，就是刚刚建立的XXX.github.io仓库的地址，output路径在系统中的源文件夹处可以看到。如果是从hexo迁移过来的话，这个时候一般只要拷贝一下就行了，但是需要保证之前的git origin 地址是正确的。</li>
</ol>
<h2 id="参考文档">参考文档</h2>
<p>搭建过程中查阅的相关文档，其实就是官方的文档😜</p>
<ul>
<li><a href="https://gridea.dev/">Gridea文档</a></li>
<li><a href="https://fehey.com/post/hve-notes-start/">Gridea小白上手教程</a></li>
<li><a href="https://www.bilibili.com/video/av54010923">B站视频教程</a></li>
</ul>
]]></content>
    </entry>
</feed>